<!DOCTYPE html>
<html lang="en">
<head>
        <title>Compile-toi toi même</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="http://compiletoi.net/theme/css/main.css" type="text/css" />
        <link href="http://compiletoi.net/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Compile-toi toi même Atom Feed" />
        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://compiletoi.net/css/ie.css"/>
                <script src="http://compiletoi.net/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="http://compiletoi.net/css/ie6.css"/><![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="http://compiletoi.net">Compile-toi toi même  <strong>(Georges Dubus)</strong></a></h1>
                <nav><ul>
                    <li><a href="/archives.html">Archives</a></li>
                    <li><a href="/tags.html">Tags</a></li>
                    <li ><a href="http://compiletoi.net/category/misc.html">misc</a></li>
                    <li ><a href="http://compiletoi.net/category/python.html">python</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article class="mainarticle">
                    <h1 class="entry-title"><a href="http://compiletoi.net/fast-scraping-in-python-with-asyncio.html">Fast scraping in python with asyncio</a></h1>
<footer class="post-info">
        <abbr class="published" title="2014-03-02T17:50:00">
                Sun 02 March 2014
        </abbr>

<p>In <a href="http://compiletoi.net/category/python.html">python</a>. </p>
<p>tags: <a href="http://compiletoi.net/tag/python.html">python</a></p></footer><!-- /.post-info --><p>Web scraping is one of those subjects that often appears in python
discussions. There are many ways to do this, and there doesn't seem to
be one best way. There are fully fledged frameworks like <a class="reference external" href="http://scrapy.org">scrapy</a> and more
lightweight libraries like <a class="reference external" href="http://wwwsearch.sourceforge.net/mechanize/">mechanize</a>. Do-it-yourself solutions are
also popular: one can go a long way by using <a class="reference external" href="http://python-requests.org/">requests</a> and
<a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/">beautifulsoup</a> or <a class="reference external" href="http://pythonhosted.org/pyquery/">pyquery</a>.</p>
<p>The reason for this diversity is that &quot;scraping&quot; actually covers
multiple problems: you don't need to same tool to extract data from
hundreds of pages and to automate some web workflow (like filling a
few forms and getting some data back). I like the do-it-yourself
approach because it's flexible, but it's not well-suited for massive
data extraction, because <cite>requests</cite> does requests synchronously, and
many requests means you have to wait a long time.</p>
<p>In this blog post, I'll present you an alternative to <cite>requests</cite> based
on the new asyncio library : <a class="reference external" href="https://github.com/KeepSafe/aiohttp">aiohttp</a>. I use it to write small
scraper that are really fast, and I'll show you how.</p>
<div class="section" id="basics-of-asyncio">
<h2>Basics of asyncio</h2>
<p><a class="reference external" href="http://docs.python.org/3.4/library/asyncio.html">asyncio</a> is the asynchronous IO library that was introduced in python
3.4. You can also get it from pypi on python 3.3. It's quite complex
and I won't go too much into details. Instead, I'll explain what you
need to know to write asynchronous code with it. If you want to know
more about, I invite you to read its documentation.</p>
<p>To make it simple, there are two things you need to know about :
coroutines and event loops. Coroutines are like functions, but they can
be suspended or resumed at certain points in the code. This is used to
pause a coroutine while it waits for an IO (an HTTP request, for
example) and execute another one in the meantime. We use the <tt class="docutils literal">yield
from</tt> keyword to state that we want the return value of a
coroutine. An event loop is used to orchestrate the execution of the coroutines.</p>
<p>There is much more to asyncio, but that's all we need to know for
now. It might be a little unclear from know, so let's look at some code.</p>
</div>
<div class="section" id="id1">
<h2>aiohttp</h2>
<p><a class="reference external" href="https://github.com/KeepSafe/aiohttp">aiohttp</a> is a library designed to work with asyncio, with an API that
looks like requests'. It's not very well documented for now, but there
are some very useful <a class="reference external" href="https://github.com/KeepSafe/aiohttp/tree/master/examples">examples</a>. We'll first show its basic usage.</p>
<p>First, we'll define a coroutine to get a page and print it. We use
<tt class="docutils literal">asyncio.coroutine</tt> to decorate a function as a
coroutine. <tt class="docutils literal">aiohttp.request</tt> is a coroutine, and so is the <tt class="docutils literal">read</tt>
method, so we'll need to use <tt class="docutils literal">yield from</tt> to call them. Apart from
that, the code looks pretty straightforward:</p>
<div class="highlight"><pre><span class="nd">@asyncio.coroutine</span>
<span class="k">def</span> <span class="nf">print_page</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="s">&#39;GET&#39;</span><span class="p">,</span> <span class="n">url</span><span class="p">)</span>
    <span class="n">body</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">read_and_close</span><span class="p">(</span><span class="n">decode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">body</span><span class="p">)</span>
</pre></div>
<p>As we have seen, we can call a coroutine from another coroutine with
<tt class="docutils literal">yield from</tt>. To call a coroutine from synchronous code, we'll need an
event loop. We can get the standard one with
<tt class="docutils literal">asyncio.get_event_loop()</tt> and run the coroutine on it using its
<tt class="docutils literal">run_until_complete()</tt> method. So, all we have to do to run the
previous coroutine is:</p>
<div class="highlight"><pre><span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
<span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span><span class="n">print_page</span><span class="p">(</span><span class="s">&#39;http://example.com&#39;</span><span class="p">))</span>
</pre></div>
<p>A useful function is <tt class="docutils literal">asyncio.wait</tt>, which takes a list a coroutines
and returns a single coroutine that wrap them all, so we can write:</p>
<div class="highlight"><pre><span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span><span class="n">asyncio</span><span class="o">.</span><span class="n">wait</span><span class="p">([</span><span class="n">print_page</span><span class="p">(</span><span class="s">&#39;http://example.com/foo&#39;</span><span class="p">),</span>
                                      <span class="n">print_page</span><span class="p">(</span><span class="s">&#39;http://example.com/bar&#39;</span><span class="p">)]))</span>
</pre></div>
<p>Another one is <tt class="docutils literal">asyncio.as_completed</tt>, that takes a list of coroutines
and returns an iterator that yields the coroutines in the order in which
they are completed, so that when you iterate on it, you get each
result as soon as it's available.</p>
</div>
<div class="section" id="scraping">
<h2>Scraping</h2>
<p>Now that we know how to do asynchronous HTTP requests, we can write a
scraper. The only other part we need is something to read the html. I
use <a class="reference external" href="http://www.crummy.com/software/BeautifulSoup/">beautifulsoup</a> for that, be others like <a class="reference external" href="http://pythonhosted.org/pyquery/">pyquery</a> or <a class="reference external" href="http://lxml.de/">lxml</a>.</p>
<p>For this example, we'll write a small scraper to get the torrent
links for various linux distributions from the pirate bay.</p>
<p>First of all, a helper coroutine to perform GET requests:</p>
<div class="highlight"><pre><span class="nd">@asyncio.coroutine</span>
<span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">aiohttp</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="s">&#39;GET&#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">read_and_close</span><span class="p">(</span><span class="n">decode</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</pre></div>
<p>The parsing part. This post is not about beautifulsoup, so I'll keep
it dumb and simple: we get the first magnet list of the page:</p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">first_magnet</span><span class="p">(</span><span class="n">page</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">bs4</span><span class="o">.</span><span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Download this torrent using magnet&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">a</span><span class="p">[</span><span class="s">&#39;href&#39;</span><span class="p">]</span>
</pre></div>
<p>The coroutine. With this url, results are sorted by number of seeders,
so the first result is actually the most seeded:</p>
<div class="highlight"><pre><span class="nd">@asyncio.coroutine</span>
<span class="k">def</span> <span class="nf">print_magnet</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">&#39;http://thepiratebay.se/search/{}/0/7/0&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="n">page</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">magnet</span> <span class="o">=</span> <span class="n">first_magnet</span><span class="p">(</span><span class="n">page</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&#39;{}: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">magnet</span><span class="p">))</span>
</pre></div>
<p>Finally, the code to call all of this:</p>
<div class="highlight"><pre><span class="n">distros</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;archlinux&#39;</span><span class="p">,</span> <span class="s">&#39;ubuntu&#39;</span><span class="p">,</span> <span class="s">&#39;debian&#39;</span><span class="p">]</span>
<span class="n">loop</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">get_event_loop</span><span class="p">()</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">wait</span><span class="p">([</span><span class="n">print_magnet</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">distros</span><span class="p">])</span>
<span class="n">loop</span><span class="o">.</span><span class="n">run_until_complete</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion</h2>
<p>And there you go, you have a small scraper that works
asynchronously. That means the various pages are being downloaded at
the same time, so this example is 3 times faster than the same code
with <cite>requests</cite>. You should now be able to write your own scrapers in
the same way.</p>
<p>You can find the resulting code, including the bonus tracks, in this
<a class="reference external" href="https://gist.github.com/madjar/9312452">gist</a>.</p>
<p>Once you are comfortable with all this, I recommend you take a look at
<a class="reference external" href="http://docs.python.org/3.4/library/asyncio.html">asyncio</a>'s documentation and aiohttp <a class="reference external" href="https://github.com/KeepSafe/aiohttp/tree/master/examples">examples</a>, which will show you
all the potential asyncio has.</p>
<p>One limitation of this approach (in fact, any hand-made approach) is
that there doesn't seem to be a standalone library to handle
forms. Mechanize and scrapy have nice helpers to easily submit forms,
but if you don't use them, you'll have to do it yourself. This is
something that bugs be, so I might write such a library at some point
(but don't count on it for now).</p>
</div>
<div class="section" id="bonus-track-don-t-hammer-the-server">
<h2>Bonus track: don't hammer the server</h2>
<p>Doing 3 requests at the same time is cool, doing 5000, however, is not
so nice. If you try to do too many requests at the same time,
connections might start to get closed, or you might even get banned
from the website.</p>
<p>To avoid this, you can use a <a class="reference external" href="http://docs.python.org/3.4/library/asyncio-sync.html#semaphores">semaphore</a>. It is a synchronization tool
that can be used to limit the number of coroutines that do something
at some point. We'll just create the semaphore before creating the
loop, passing as an argument the number of simultaneous requests we
want to allow:</p>
<div class="highlight"><pre><span class="n">sem</span> <span class="o">=</span> <span class="n">asyncio</span><span class="o">.</span><span class="n">Semaphore</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
<p>Then, we just replace:</p>
<div class="highlight"><pre><span class="n">page</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<p>by the same thing, but protected by a semaphore:</p>
<div class="highlight"><pre><span class="k">with</span> <span class="p">(</span><span class="k">yield from</span> <span class="n">sem</span><span class="p">):</span>
    <span class="n">page</span> <span class="o">=</span> <span class="k">yield from</span> <span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">compress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
<p>This will ensure that at most 5 requests can be done at the same time.</p>
</div>
<div class="section" id="bonus-track-progress-bar">
<h2>Bonus track: progress bar</h2>
<p>This one is just for free: <a class="reference external" href="https://github.com/noamraph/tqdm">tqdm</a> is a nice library to make progress
bars. This coroutine works just like <tt class="docutils literal">asyncio.wait</tt>, but displays a
progress bar indicating the completion of the coroutines passed to
it:</p>
<div class="highlight"><pre><span class="nd">@asyncio.coroutine</span>
<span class="k">def</span> <span class="nf">wait_with_progress</span><span class="p">(</span><span class="n">coros</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">asyncio</span><span class="o">.</span><span class="n">as_completed</span><span class="p">(</span><span class="n">coros</span><span class="p">),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">coros</span><span class="p">)):</span>
        <span class="k">yield from</span> <span class="n">f</span>
</pre></div>
</div>
<p>There are <a href="http://compiletoi.net/fast-scraping-in-python-with-asyncio.html#disqus_thread">comments</a>.</p>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                        <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                        <h1><a href="http://compiletoi.net/pyramid-advanced-configuration-tactics-for-nice-apps-and-libs.html" rel="bookmark" title="Permalink to Pyramid advanced configuration tactics for nice apps and libs">Pyramid advanced configuration tactics for nice apps and libs</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2013-12-19T14:30:00">
                Thu 19 December 2013
        </abbr>

<p>In <a href="http://compiletoi.net/category/python.html">python</a>. </p>
<p>tags: <a href="http://compiletoi.net/tag/pyramid.html">pyramid</a><a href="http://compiletoi.net/tag/python.html">python</a></p></footer><!-- /.post-info -->                <p>Pyramid is a great framework, and one of the things that makes it
great is its configuration system, which provide both a great way to
organize an application, and an elegant system to write
extensions.</p>
<p>This talk explain how the configuration system works and how
to use it, then uses ...</p>
                <a class="readmore" href="http://compiletoi.net/pyramid-advanced-configuration-tactics-for-nice-apps-and-libs.html">read more</a>
<p>There are <a href="http://compiletoi.net/pyramid-advanced-configuration-tactics-for-nice-apps-and-libs.html#disqus_thread">comments</a>.</p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                        <h1><a href="http://compiletoi.net/quick-authentication-on-pyramid-with-persona.html" rel="bookmark" title="Permalink to Quick authentication on pyramid with persona">Quick authentication on pyramid with persona</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2012-09-01T15:30:00">
                Sat 01 September 2012
        </abbr>

<p>In <a href="http://compiletoi.net/category/python.html">python</a>. </p>
<p>tags: <a href="http://compiletoi.net/tag/pyramid.html">pyramid</a><a href="http://compiletoi.net/tag/persona.html">persona</a><a href="http://compiletoi.net/tag/python.html">python</a></p></footer><!-- /.post-info -->                <p>A few days ago, the first beta of <a class="reference external" href="https://login.persona.org/">persona</a> was released, and I thought
it would be nice to try it as a authentication mechanism in my next
project. For the pyramid framework, the persona documentation pointed
to this blog post : <a class="reference external" href="http://www.rfk.id.au/blog/entry/painless-auth-pyramid-browserid/">Painless Authentication with Pyramid and
BrowserID</a>, which describes how ...</p>
                <a class="readmore" href="http://compiletoi.net/quick-authentication-on-pyramid-with-persona.html">read more</a>
<p>There are <a href="http://compiletoi.net/quick-authentication-on-pyramid-with-persona.html#disqus_thread">comments</a>.</p>                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                        <h1><a href="http://compiletoi.net/good-evening-ladies-and-gentlemen.html" rel="bookmark" title="Permalink to Good evening ladies and gentlemen, parlez vous français ?">Good evening ladies and gentlemen, parlez vous français ?</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2012-06-03T17:20:00">
                Sun 03 June 2012
        </abbr>

<p>In <a href="http://compiletoi.net/category/misc.html">misc</a>. </p>
<p>tags: <a href="http://compiletoi.net/tag/pelican.html">pelican</a><a href="http://compiletoi.net/tag/emacs.html">emacs</a><a href="http://compiletoi.net/tag/github.html">github</a><a href="http://compiletoi.net/tag/blog.html">blog</a></p></footer><!-- /.post-info -->                <p>Hi, I'm Georges Dubus, I'm a french PhD student doing some hacking on
his free time, and here is my tentative of a blog.</p>
<p>I have wanted to start a blog for a long time, but never really did it
by lack of content idea, motivation, and platform ...</p>
                <a class="readmore" href="http://compiletoi.net/good-evening-ladies-and-gentlemen.html">read more</a>
<p>There are <a href="http://compiletoi.net/good-evening-ladies-and-gentlemen.html#disqus_thread">comments</a>.</p>                </div><!-- /.entry-content -->
            </article></li>
<p class="paginator">
    Page 1 / 1
</p>
    </ol><!-- /#posts-list -->
    </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="http://compiletoi.net/" rel="alternate">atom feed</a></li>

                            <li><a href="https://github.com/madjar">Github</a></li>
                            <li><a href="http://twitter.com/georgesdubus">Twitter</a></li>
                            <li><a href="https://plus.google.com/u/0/104750974388692229541">Google+</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->


    <script type="text/javascript">
    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
    </script>
    <script type="text/javascript">
    try {
        var pageTracker = _gat._getTracker("UA-31800325-1");
    pageTracker._trackPageview();
    setTimeout("pageTracker._trackEvent('1_minute', 'read')",60000);
    } catch(err) {}</script>
<script type="text/javascript">
    var disqus_shortname = 'compiletoi';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>